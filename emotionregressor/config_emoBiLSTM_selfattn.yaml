configuration:
  Name: BiLSTM_SelfAttn_EmoRegressor
  embeddings:
    embed_size: 128
  inference:
    beam_size: 5
    infer_batch_size: 15
    infer_source_file: ./example/dev_source.txt
    infer_source_max_length: 25
    max_length: 20
    output_path: ./prediction.txt
    type: beam_search
  model:
    bidirectional: true
    cell_type: LSTM
    num_attn_hidden: 128
    num_emotions: 4
    num_layers: 2
    num_units: 256
    self_attention: true
  training:
    batch_size: 64
    checkpoint_every: 500
    gpu_fraction: 0.05
    l2_regularize: null
    learning_rate: 0.001
    logdir: ./log_emoReg/
    loss_fig: ./training_loss_over_time
    max_checkpoints: 10000
    max_length: 25
    pearson_fig: ./pearson_over_time
    print_every: 20
    restore_from: ./log_emoReg/
    train_steps: 4000
